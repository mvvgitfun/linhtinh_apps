import streamlit as st
import pandas as pd
import json
from google.cloud import bigquery
from google.oauth2 import service_account
from io import BytesIO
from collections import Counter
import re

# optional translation lib
try:
    from googletrans import Translator
    TRANSLATOR_AVAILABLE = True
except Exception:
    TRANSLATOR_AVAILABLE = False

# ================== CONFIG ==================
st.set_page_config(page_title="üìä Game Review Analytics", layout="wide")

st.markdown(
    "<h1 style='text-align: center;'>üìä Game Review Analytics Dashboard üéÆ</h1>",
    unsafe_allow_html=True,
)

# ================== BIGQUERY CONNECT ==================
# L·∫•y credentials t·ª´ Streamlit secrets (st.secrets["bigquery"] should be the JSON structure)
sa_info = st.secrets["bigquery"]
creds = service_account.Credentials.from_service_account_info(sa_info)
client = bigquery.Client(credentials=creds, project=creds.project_id)

# ================== LOAD DATA ==================
@st.cache_data(ttl=600)
def load_data():
    query = """
        SELECT
            `Package Name` AS package_name,
            `App Version Name` AS app_version,
            `Reviewer Language` AS reviewer_lang,
            `Device` AS device,
            `Review Submit Date and Time` AS review_time,
            SAFE_CAST(`Star Rating` AS INT64) AS star_rating,
            `Review Title` AS review_title,
            `Review Text` AS review_text,
            `Developer Reply Text` AS dev_reply
        FROM `mps-data-139.gpc_reviews_viz.reviews`
        WHERE `Package Name` IS NOT NULL
    """
    df = client.query(query).to_dataframe()
    return df

df = load_data()

# Normalize columns
df["review_text"] = df["review_text"].astype("string")
df["review_time"] = pd.to_datetime(df["review_time"], errors="coerce")
df["date"] = df["review_time"].dt.date

# ================== SIDEBAR CONTROLS ==================
st.sidebar.header("Filters & Options")
apps = df["package_name"].dropna().unique().tolist()
selected_app = st.sidebar.selectbox("üéÆ Ch·ªçn game (package name)", apps)

# Version filter
df_app_all = df[df["package_name"] == selected_app].copy()
versions = ["T·∫•t c·∫£"] + sorted(df_app_all["app_version"].dropna().unique().tolist())
selected_version = st.sidebar.selectbox("üõ† Ch·ªçn phi√™n b·∫£n", versions)

# Translation option
translate_enable = st.sidebar.checkbox("üåê D·ªãch review sang ti·∫øng Anh (Translate to English)", value=False)
# If translator not installed, show warning and disable
if translate_enable and not TRANSLATOR_AVAILABLE:
    st.sidebar.error("Module `googletrans` ch∆∞a c√†i. Ch·∫°y: pip install googletrans==4.0.0-rc1")
    translate_enable = False

# Analysis options
use_translated_for_analysis = st.sidebar.checkbox("üîé D√πng ti·∫øng Anh ƒë·ªÉ ph√¢n t√≠ch (n·∫øu c√≥)", value=True)
min_word_count = st.sidebar.number_input("Min words to consider review text", min_value=0, max_value=500, value=1)

# ================== SELECT DATA SLICE ==================
df_app = df_app_all.copy()
if selected_version != "T·∫•t c·∫£":
    df_app = df_app[df_app["app_version"] == selected_version].copy()

# ================== TRANSLATION HELPERS ==================
# Caching translations to avoid repeat network calls
@st.cache_data(ttl=3600)
def translate_texts_batch(texts, dest="en"):
    """
    texts: list[str] (can include None/empty)
    returns: list[str] translated (original if fail/empty)
    """
    if not TRANSLATOR_AVAILABLE:
        return texts
    translator = Translator()
    translated = []
    # chunk to avoid huge requests
    CHUNK = 50
    for i in range(0, len(texts), CHUNK):
        chunk = texts[i:i+CHUNK]
        strs = ["" if (t is None or str(t).strip() == "") else str(t) for t in chunk]
        try:
            res = translator.translate(strs, dest=dest)
            # res may be single object or list
            if isinstance(res, list):
                translated.extend([r.text if getattr(r, "text", None) is not None else "" for r in res])
            else:
                translated.append(res.text if getattr(res, "text", None) is not None else "")
        except Exception as e:
            # fallback: keep original if translation fails
            translated.extend(strs)
    return translated

# Prepare translation column if enabled
if translate_enable:
    st.info("ƒêang d·ªãch review sang ti·∫øng Anh (caching ƒë·ªÉ gi·∫£m requests)...")
    texts = df_app["review_text"].fillna("").astype(str).tolist()
    translated_list = translate_texts_batch(texts, dest="en")
    # store a new column
    df_app["review_text_en"] = translated_list
else:
    # keep english column same as original if not translating
    df_app["review_text_en"] = df_app["review_text"]

# choose which text to use for analysis
if use_translated_for_analysis:
    analysis_text_col = "review_text_en"
else:
    analysis_text_col = "review_text"

# ================== METRICS ==================
st.subheader(f"üì¶ ƒêang xem: {selected_app}  ‚Äî  Phi√™n b·∫£n: {selected_version}")

col1, col2, col3 = st.columns(3)
with col1:
    st.metric("üë• T·ªïng s·ªë review", df_app.shape[0])
with col2:
    st.metric("üí¨ C√≥ review text", int(df_app["review_text"].astype(bool).sum()))
with col3:
    avg_rating = df_app["star_rating"].dropna()
    st.metric("‚≠ê ƒêi·ªÉm trung b√¨nh", round(avg_rating.mean(), 2) if not avg_rating.empty else "N/A")

# ================== DISTRIBUTIONS ==================
st.subheader("‚≠ê Ph√¢n b·ªë Rating")
rating_counts = df_app["star_rating"].value_counts().sort_index()
st.bar_chart(rating_counts)

st.subheader("‚è± Review theo th·ªùi gian (s·ªë l∆∞·ª£ng / ng√†y)")
time_series = df_app.groupby("date").size().rename("count")
st.line_chart(time_series)

# ================== ISSUE ANALYSIS (LOW RATINGS) ==================
st.subheader("üîç Ph√¢n t√≠ch l√Ω do rating th·∫•p (1-2 sao)")

low_reviews = df_app[(df_app["star_rating"] <= 2) & (df_app[analysis_text_col].notna())].copy()
low_reviews["analysis_text"] = low_reviews[analysis_text_col].astype(str)

# Predefined keywords mapping (you can extend)
issues_keywords = {
    r"\blag\b": "Lag / Slow",
    r"\bslow\b": "Lag / Slow",
    r"\bcrash\b": "Crash",
    r"\bforce close\b": "Crash",
    r"\bad(s)?\b": "Too Many Ads",
    r"\bads\b": "Too Many Ads",
    r"\bcontrol(s)?\b": "Control Issues",
    r"\bbug\b": "Bug",
    r"\berror\b": "Error",
    r"\bpay(ment)?\b": "Monetization / Payment",
    r"\binstall\b": "Install / Update Issues",
    r"\bconnect(ion)?\b": "Connection / Network",
}

def detect_issue_from_text(text):
    if not text or text.strip() == "":
        return None
    t = text.lower()
    for pattern, label in issues_keywords.items():
        if re.search(pattern, t):
            return label
    return None

if not low_reviews.empty:
    low_reviews["detected_issue"] = low_reviews["analysis_text"].apply(detect_issue_from_text)
    issue_counts = low_reviews["detected_issue"].value_counts(dropna=True)
    if not issue_counts.empty:
        st.bar_chart(issue_counts)
    else:
        st.info("Kh√¥ng ph√°t hi·ªán keyword issue n√†o ph·ªï bi·∫øn ‚Äî b·∫°n c√≥ th·ªÉ m·ªü r·ªông danh s√°ch `issues_keywords`.")
    # show sample
    st.subheader("üìã M·ªôt s·ªë review 1-2‚òÖ (k√®m b·∫£n d·ªãch n·∫øu b·∫≠t)")
    # Show original lang and translated text (if translated)
    show_cols = ["star_rating", "reviewer_lang", "analysis_text", "detected_issue"]
    st.dataframe(low_reviews[show_cols].rename(columns={"analysis_text": "Review (analysis text)"}).head(50))
else:
    st.info("Kh√¥ng c√≥ review 1-2‚òÖ ƒë·ªÉ ph√¢n t√≠ch trong t·∫≠p d·ªØ li·ªáu ƒë√£ ch·ªçn.")

# ================== WORDCLOUD ==================
st.subheader("‚òÅÔ∏è WordCloud t·ª´ review text (d√πng text ph√¢n t√≠ch)")

# WordCloud only if there is text
all_text = " ".join(df_app[analysis_text_col].dropna().astype(str).tolist())
if all_text.strip():
    try:
        from wordcloud import WordCloud
        import matplotlib.pyplot as plt
        # prepare stopwords (add some common tokens, optionally extend by language)
        from wordcloud import STOPWORDS
        stopwords = set(STOPWORDS)
        # add short words and obvious words
        extra_stops = {"game", "play", "one", "like", "good", "dont", "dont", "dont", "the", "and"}
        stopwords.update(extra_stops)

        wc = WordCloud(width=800, height=400, background_color="white", stopwords=stopwords, max_words=200).generate(all_text)

        fig, ax = plt.subplots(figsize=(12, 6))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
    except Exception as e:
        st.error("WordCloud kh√¥ng th·ªÉ t·∫°o (thi·∫øu package?). C√†i: pip install wordcloud matplotlib")
else:
    st.info("Kh√¥ng c√≥ review text ƒë·ªÉ t·∫°o WordCloud.")

# ================== RAW DATA (with translation column) ==================
st.subheader("üìú D·ªØ li·ªáu g·ªëc (c√≥ c·ªôt b·∫£n d·ªãch khi b·∫≠t)")

# Prepare display dataframe
display_cols = ["review_time", "star_rating", "reviewer_lang", "device", "review_text"]
if translate_enable:
    display_cols += ["review_text_en"]
st.dataframe(df_app[display_cols].sort_values(by="review_time", ascending=False).reset_index(drop=True), height=400)

# ================== DOWNLOAD ==================
def to_excel_bytes(df_export: pd.DataFrame) -> bytes:
    with BytesIO() as buffer:
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            df_export.to_excel(writer, index=False, sheet_name="Reviews")
        return buffer.getvalue()

st.download_button(
    "‚¨áÔ∏è T·∫£i d·ªØ li·ªáu (.xlsx)",
    to_excel_bytes(df_app),
    file_name=f"{selected_app}_reviews.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

# ================== NOTES & HELP ==================
st.markdown("""
**Ghi ch√∫**
- D·ªãch d√πng package `googletrans`; c√≥ th·ªÉ b·ªã rate-limit ho·∫∑c kh√¥ng ho√†n h·∫£o ‚Äî n·∫øu g·∫∑p l·ªói, t·∫Øt option translate.
- `st.secrets["bigquery"]` ph·∫£i ch·ª©a JSON c·ªßa service account (copy nguy√™n file service_account.json v√†o Streamlit secrets).
- N·∫øu mu·ªën c·∫£i thi·ªán ph√¢n lo·∫°i issue, m·ªü r·ªông `issues_keywords`.
""")
